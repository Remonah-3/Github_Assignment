{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpNDcXAMPQlBd+FtLWGpsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Remonah-3/Github_Assignment/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4wxAHprx-qkp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    z = z - np.max(z, axis=1, keepdims=True)\n",
        "    exp_z = np.exp(z)\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "class SimpleRNN:\n",
        "    def __init__(self, n_features, n_nodes, w_x=None, w_h=None, b=None):\n",
        "        self.n_features = n_features\n",
        "        self.n_nodes = n_nodes\n",
        "        if w_x is None:\n",
        "            self.W_x = np.random.randn(n_features, n_nodes) * 0.01\n",
        "        else:\n",
        "            self.W_x = np.array(w_x, dtype=float)\n",
        "        if w_h is None:\n",
        "            self.W_h = np.random.randn(n_nodes, n_nodes) * 0.01\n",
        "        else:\n",
        "            self.W_h = np.array(w_h, dtype=float)\n",
        "        if b is None:\n",
        "            self.b = np.zeros(n_nodes, dtype=float)\n",
        "        else:\n",
        "            self.b = np.array(b, dtype=float).reshape(-1)\n",
        "\n",
        "    def forward(self, x, h0=None, return_all=False):\n",
        "        batch_size, n_sequences, n_features = x.shape\n",
        "        if n_features != self.n_features:\n",
        "            raise ValueError(\"x feature dimension mismatch\")\n",
        "        if h0 is None:\n",
        "            h = np.zeros((batch_size, self.n_nodes))\n",
        "        else:\n",
        "            h = np.array(h0, dtype=float)\n",
        "            if h.shape != (batch_size, self.n_nodes):\n",
        "                raise ValueError(\"h0 shape mismatch\")\n",
        "        h_all = []\n",
        "        for t in range(n_sequences):\n",
        "            x_t = x[:, t, :]\n",
        "            a_t = x_t @ self.W_x + h @ self.W_h + self.b\n",
        "            h = np.tanh(a_t)\n",
        "            if return_all:\n",
        "                h_all.append(h.copy())\n",
        "        if return_all:\n",
        "            h_all = np.stack(h_all, axis=1)\n",
        "            return h, h_all\n",
        "        return h\n",
        "\n",
        "class ScratchSimpleRNNClassifier:\n",
        "    def __init__(self, rnn, n_classes, dense_w=None, dense_b=None):\n",
        "        self.rnn = rnn\n",
        "        self.n_classes = n_classes\n",
        "        if dense_w is None:\n",
        "            self.dense_w = np.random.randn(rnn.n_nodes, n_classes) * 0.01\n",
        "        else:\n",
        "            self.dense_w = np.array(dense_w, dtype=float)\n",
        "        if dense_b is None:\n",
        "            self.dense_b = np.zeros(n_classes, dtype=float)\n",
        "        else:\n",
        "            self.dense_b = np.array(dense_b, dtype=float).reshape(-1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        h_final = self.rnn.forward(X)\n",
        "        logits = h_final @ self.dense_w + self.dense_b\n",
        "        return softmax(logits)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = self.predict_proba(X)\n",
        "        return np.argmax(probs, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
        "batch_size = x.shape[0] # 1\n",
        "n_sequences = x.shape[1] # 3\n",
        "n_features = x.shape[2] # 2\n",
        "n_nodes = w_x.shape[1] # 4\n",
        "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
        "b = np.array([1, 1, 1, 1]) # (n_nodes,)\n",
        "\n",
        "for t in range(n_sequences):\n",
        "    a_t = np.dot(x[:, t, :], w_x) + np.dot(h, w_h) + b\n",
        "    h = np.tanh(a_t)\n",
        "\n",
        "print(h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7XgovkM-r8H",
        "outputId": "056dbc9e-14c6-4588-9adc-8900feffdf92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def rnn_backprop(x, h_list, a_list, w_x, w_h, b, dh_final, learning_rate=0.01):\n",
        "    batch_size, n_sequences, n_features = x.shape\n",
        "    n_nodes = w_x.shape[1]\n",
        "\n",
        "    dW_x = np.zeros_like(w_x)\n",
        "    dW_h = np.zeros_like(w_h)\n",
        "    dB   = np.zeros_like(b)\n",
        "\n",
        "    dh_next = dh_final.copy()\n",
        "\n",
        "    for t in reversed(range(n_sequences)):\n",
        "        h_t = h_list[t+1]\n",
        "        h_prev = h_list[t]\n",
        "        a_t = a_list[t]\n",
        "\n",
        "        delta = dh_next * (1 - h_t**2)\n",
        "        dB   += np.sum(delta, axis=0)\n",
        "        dW_x += x[:, t, :].T @ delta\n",
        "        dW_h += h_prev.T @ delta\n",
        "        dh_next = delta @ w_h.T\n",
        "\n",
        "    w_x -= learning_rate * dW_x\n",
        "    w_h -= learning_rate * dW_h\n",
        "    b   -= learning_rate * dB\n",
        "\n",
        "    return w_x, w_h, b"
      ],
      "metadata": {
        "id": "nxvirp08-5EX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-LXcKYZ-F2DO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}