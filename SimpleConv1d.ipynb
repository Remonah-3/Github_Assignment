{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5+BfydqWHen0aHS56+ReL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Remonah-3/Github_Assignment/blob/master/SimpleConv1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7dCIlsxozNWa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size, learning_rate=0.01):\n",
        "        self.filter_size = filter_size\n",
        "        self.learning_rate = learning_rate\n",
        "        # Xavier initialization (float)\n",
        "        self.w = np.random.randn(filter_size).astype(float) * np.sqrt(1.0 / filter_size)\n",
        "        self.b = 0.0  # scalar float bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x.astype(float)  # ensure float\n",
        "        output_length = len(self.x) - self.filter_size + 1\n",
        "        self.a = np.empty(output_length, dtype=float)\n",
        "        for i in range(output_length):\n",
        "            self.a[i] = np.sum(self.x[i:i+self.filter_size] * self.w) + self.b\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        delta_w = np.zeros_like(self.w, dtype=float)\n",
        "        delta_b = np.sum(delta_a)\n",
        "        delta_x = np.zeros_like(self.x, dtype=float)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv1d_output_size(input_size, filter_size, padding=0, stride=1):\n",
        "    return (input_size + 2*padding - filter_size)//stride + 1\n",
        "\n",
        "# Example\n",
        "print(conv1d_output_size(4, 3))  # Output: 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ojokkuzPHL",
        "outputId": "a6bb22cb-0a1c-4053-d0bc-f4efbcd947c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3, 4], dtype=float)\n",
        "w = np.array([3, 5, 7], dtype=float)\n",
        "b = 1.0\n",
        "\n",
        "conv = SimpleConv1d(filter_size=3)\n",
        "conv.w = w.copy()\n",
        "conv.b = b\n",
        "\n",
        "# Forward\n",
        "a = conv.forward(x)\n",
        "print(\"Forward output:\", a)  # [35, 50]\n",
        "\n",
        "# Backward\n",
        "delta_a = np.array([10, 20], dtype=float)\n",
        "delta_x = conv.backward(delta_a)\n",
        "print(\"Updated w:\", conv.w)\n",
        "print(\"Updated b:\", conv.b)\n",
        "print(\"Delta x:\", delta_x)   # [30, 110, 170, 140]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfYEE2ymzPRx",
        "outputId": "d560e2d9-1323-461e-dcb1-c132184b1e13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward output: [35. 50.]\n",
            "Updated w: [3. 5. 7.]\n",
            "Updated b: 1.0\n",
            "Delta x: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1d:\n",
        "    def __init__(self, input_channels, output_channels, filter_size, learning_rate=0.01):\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.filter_size = filter_size\n",
        "        self.lr = learning_rate\n",
        "\n",
        "        # Weights: (output_channels, input_channels, filter_size) float\n",
        "        self.w = np.random.randn(output_channels, input_channels, filter_size).astype(float) * np.sqrt(1.0/filter_size)\n",
        "        self.b = np.zeros(output_channels, dtype=float)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x.astype(float)\n",
        "        output_length = x.shape[1] - self.filter_size + 1\n",
        "        a = np.zeros((self.output_channels, output_length), dtype=float)\n",
        "\n",
        "        for o in range(self.output_channels):\n",
        "            for i in range(self.input_channels):\n",
        "                for j in range(output_length):\n",
        "                    a[o, j] += np.sum(self.x[i, j:j+self.filter_size] * self.w[o, i])\n",
        "            a[o] += self.b[o]\n",
        "\n",
        "        self.a = a\n",
        "        return a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        delta_w = np.zeros_like(self.w, dtype=float)\n",
        "        delta_b = np.sum(delta_a, axis=1)\n",
        "        delta_x = np.zeros_like(self.x, dtype=float)\n",
        "\n",
        "        output_length = delta_a.shape[1]\n",
        "\n",
        "        for o in range(self.output_channels):\n",
        "            for i in range(self.input_channels):\n",
        "                for j in range(output_length):\n",
        "                    delta_w[o, i] += delta_a[o, j] * self.x[i, j:j+self.filter_size]\n",
        "                    delta_x[i, j:j+self.filter_size] += delta_a[o, j] * self.w[o, i]\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.w -= self.lr * delta_w\n",
        "        self.b -= self.lr * delta_b\n",
        "\n",
        "        return delta_x\n"
      ],
      "metadata": {
        "id": "rG7E7OLjzPaM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_input(x, pad_width):\n",
        "    # x: (channels, length), pad_width: int\n",
        "    return np.pad(x, ((0,0),(pad_width, pad_width)), mode='constant')\n",
        "\n",
        "x = np.array([[1,2,3,4],[2,3,4,5]], dtype=float)\n",
        "x_padded = pad_input(x, 1)\n",
        "print(x_padded)  # shape (2, 6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy2Ffv3QzPeZ",
        "outputId": "fa3acb11-fede-4d89-b037-ce6ef5ac46f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 2. 3. 4. 0.]\n",
            " [0. 2. 3. 4. 5. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_input(x, pad_width):\n",
        "    # x: (channels, length), pad_width: int\n",
        "    return np.pad(x, ((0,0),(pad_width, pad_width)), mode='constant')\n",
        "\n",
        "x = np.array([[1,2,3,4],[2,3,4,5]], dtype=float)\n",
        "x_padded = pad_input(x, 1)\n",
        "print(x_padded)  # shape (2, 6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h64e2mokzPhW",
        "outputId": "f08fe0bd-3256-4bf8-c291-da3b8530084c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 2. 3. 4. 0.]\n",
            " [0. 2. 3. 4. 5. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_batch(conv_layer, batch_x):\n",
        "    # batch_x: (batch_size, channels, length)\n",
        "    batch_out = []\n",
        "    for x in batch_x:\n",
        "        batch_out.append(conv_layer.forward(x))\n",
        "    return np.array(batch_out, dtype=float)\n"
      ],
      "metadata": {
        "id": "WEDLUFhFzPkS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1dStride(Conv1d):\n",
        "    def forward(self, x, stride=1):\n",
        "        self.x = x.astype(float)\n",
        "        output_length = (x.shape[1] - self.filter_size)//stride + 1\n",
        "        a = np.zeros((self.output_channels, output_length), dtype=float)\n",
        "\n",
        "        for o in range(self.output_channels):\n",
        "            for i in range(self.input_channels):\n",
        "                for j in range(output_length):\n",
        "                    start = j*stride\n",
        "                    a[o, j] += np.sum(x[i, start:start+self.filter_size] * self.w[o, i])\n",
        "            a[o] += self.b[o]\n",
        "\n",
        "        self.a = a\n",
        "        return a\n"
      ],
      "metadata": {
        "id": "smehchaRzPnU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Scratch1dCNNClassifier:\n",
        "    def __init__(self):\n",
        "        # 1 Conv1d layer + 1 fully connected layer\n",
        "        self.conv = Conv1d(input_channels=1, output_channels=2, filter_size=3)\n",
        "        self.fc_w = np.random.randn(2*26, 10).astype(float) * np.sqrt(1.0/26)\n",
        "        self.fc_b = np.zeros(10, dtype=float)\n",
        "        self.lr = 0.01\n",
        "\n",
        "    def forward(self, x):\n",
        "        a_conv = self.conv.forward(x)  # (channels, features)\n",
        "        self.flatten = a_conv.flatten()\n",
        "        a_fc = np.dot(self.flatten, self.fc_w) + self.fc_b\n",
        "        return a_fc\n",
        "\n",
        "    def backward(self, delta_fc):\n",
        "        delta_flat = np.dot(delta_fc, self.fc_w.T).reshape(self.conv.a.shape)\n",
        "        delta_x = self.conv.backward(delta_flat)\n",
        "\n",
        "        self.fc_w -= self.lr * np.outer(self.flatten, delta_fc)\n",
        "        self.fc_b -= self.lr * delta_fc\n",
        "        return delta_x\n"
      ],
      "metadata": {
        "id": "ymwETMbezPqU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(1,28).astype(float)  # 1D MNIST row\n",
        "y_true = np.zeros(10, dtype=float)\n",
        "y_true[3] = 1.0\n",
        "\n",
        "cnn = Scratch1dCNNClassifier()\n",
        "out = cnn.forward(x)\n",
        "loss = np.sum((out - y_true)**2)\n",
        "delta_fc = 2*(out - y_true)\n",
        "cnn.backward(delta_fc)\n",
        "\n",
        "print(\"Output:\", out)\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Feucxz1gzPsk",
        "outputId": "3de4b869-4ca3-48e4-ffb6-9fd54dc0fdc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: [-0.03287169 -0.82532792  0.43906917  0.35847874  0.06005899  0.48099938\n",
            "  0.3049069  -0.40958557  0.11540849  0.07737084]\n",
            "Loss: 1.8015794002534653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size, learning_rate=0.01):\n",
        "        self.filter_size = filter_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.w = np.random.randn(filter_size).astype(float) * np.sqrt(1.0 / filter_size)\n",
        "        self.b = 0.0\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x.astype(float)\n",
        "        output_length = len(self.x) - self.filter_size + 1\n",
        "        self.a = np.empty(output_length, dtype=float)\n",
        "        for i in range(output_length):\n",
        "            self.a[i] = np.sum(self.x[i:i+self.filter_size] * self.w) + self.b\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        delta_w = np.zeros_like(self.w, dtype=float)\n",
        "        delta_b = np.sum(delta_a)\n",
        "        delta_x = np.zeros_like(self.x, dtype=float)\n",
        "\n",
        "        for i in range(len(delta_a)):\n",
        "            delta_w += delta_a[i] * self.x[i:i+self.filter_size]\n",
        "            delta_x[i:i+self.filter_size] += delta_a[i] * self.w\n",
        "\n",
        "        self.w -= self.learning_rate * delta_w\n",
        "        self.b -= self.learning_rate * delta_b\n",
        "\n",
        "        return delta_x\n",
        "\n",
        "\n",
        "def conv1d_output_size(input_size, filter_size, padding=0, stride=1):\n",
        "    return (input_size + 2*padding - filter_size)//stride + 1\n",
        "\n",
        "\n",
        "class Conv1d:\n",
        "    def __init__(self, input_channels, output_channels, filter_size, learning_rate=0.01):\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.filter_size = filter_size\n",
        "        self.lr = learning_rate\n",
        "\n",
        "        self.w = np.random.randn(output_channels, input_channels, filter_size).astype(float) * np.sqrt(1.0/filter_size)\n",
        "        self.b = np.zeros(output_channels, dtype=float)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x.astype(float)\n",
        "        output_length = x.shape[1] - self.filter_size + 1\n",
        "        a = np.zeros((self.output_channels, output_length), dtype=float)\n",
        "\n",
        "        for o in range(self.output_channels):\n",
        "            for i in range(self.input_channels):\n",
        "                for j in range(output_length):\n",
        "                    a[o, j] += np.sum(self.x[i, j:j+self.filter_size] * self.w[o, i])\n",
        "            a[o] += self.b[o]\n",
        "\n",
        "        self.a = a\n",
        "        return a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        delta_w = np.zeros_like(self.w, dtype=float)\n",
        "        delta_b = np.sum(delta_a, axis=1)\n",
        "        delta_x = np.zeros_like(self.x, dtype=float)\n",
        "\n",
        "        output_length = delta_a.shape[1]\n",
        "\n",
        "        for o in range(self.output_channels):\n",
        "            for i in range(self.input_channels):\n",
        "                for j in range(output_length):\n",
        "                    delta_w[o, i] += delta_a[o, j] * self.x[i, j:j+self.filter_size]\n",
        "                    delta_x[i, j:j+self.filter_size] += delta_a[o, j] * self.w[o, i]\n",
        "\n",
        "        self.w -= self.lr * delta_w\n",
        "        self.b -= self.lr * delta_b\n",
        "\n",
        "        return delta_x\n",
        "\n",
        "\n",
        "def pad_input(x, pad_width):\n",
        "    return np.pad(x, ((0,0),(pad_width, pad_width)), mode='constant')\n",
        "\n",
        "\n",
        "def forward_batch(conv_layer, batch_x):\n",
        "    batch_out = []\n",
        "    for x in batch_x:\n",
        "        batch_out.append(conv_layer.forward(x))\n",
        "    return np.array(batch_out, dtype=float)\n",
        "\n",
        "\n",
        "class Conv1dStride(Conv1d):\n",
        "    def forward(self, x, stride=1):\n",
        "        self.x = x.astype(float)\n",
        "        output_length = (x.shape[1] - self.filter_size)//stride + 1\n",
        "        a = np.zeros((self.output_channels, output_length), dtype=float)\n",
        "\n",
        "        for o in range(self.output_channels):\n",
        "            for i in range(self.input_channels):\n",
        "                for j in range(output_length):\n",
        "                    start = j*stride\n",
        "                    a[o, j] += np.sum(x[i, start:start+self.filter_size] * self.w[o, i])\n",
        "            a[o] += self.b[o]\n",
        "\n",
        "        self.a = a\n",
        "        return a\n",
        "\n",
        "\n",
        "class Scratch1dCNNClassifier:\n",
        "    def __init__(self):\n",
        "        self.conv = Conv1d(input_channels=1, output_channels=2, filter_size=3)\n",
        "        self.fc_w = np.random.randn(2*26, 10).astype(float) * np.sqrt(1.0/26)\n",
        "        self.fc_b = np.zeros(10, dtype=float)\n",
        "        self.lr = 0.01\n",
        "\n",
        "    def forward(self, x):\n",
        "        a_conv = self.conv.forward(x)\n",
        "        self.flatten = a_conv.flatten()\n",
        "        a_fc = np.dot(self.flatten, self.fc_w) + self.fc_b\n",
        "        return a_fc\n",
        "\n",
        "    def backward(self, delta_fc):\n",
        "        delta_flat = np.dot(delta_fc, self.fc_w.T).reshape(self.conv.a.shape)\n",
        "        delta_x = self.conv.backward(delta_flat)\n",
        "\n",
        "        self.fc_w -= self.lr * np.outer(self.flatten, delta_fc)\n",
        "        self.fc_b -= self.lr * delta_fc\n",
        "        return delta_x\n",
        "\n",
        "\n",
        "x = np.random.rand(1,28).astype(float)\n",
        "y_true = np.zeros(10, dtype=float)\n",
        "y_true[3] = 1.0\n",
        "\n",
        "cnn = Scratch1dCNNClassifier()\n",
        "out = cnn.forward(x)\n",
        "loss = np.sum((out - y_true)**2)\n",
        "delta_fc = 2*(out - y_true)\n",
        "cnn.backward(delta_fc)\n",
        "\n",
        "print(\"Output:\", out)\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I38i8yS-zPvz",
        "outputId": "d23c933f-d632-438c-a061-728ccb38d7e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: [ 0.79685003 -0.19452464  0.42069787  0.42407782 -0.1626338   0.59624682\n",
            " -0.16123942  0.05207123 -0.31442905 -0.39443187]\n",
            "Loss: 1.8465945751210082\n"
          ]
        }
      ]
    }
  ]
}