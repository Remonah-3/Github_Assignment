{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqiVXNBesdkoVUY5KoC1Uw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Remonah-3/Github_Assignment/blob/master/SimpleConv1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 2: Calculate output size\n",
        "def conv1d_output_size(input_size, filter_size, padding=0, stride=1):\n",
        "    return (input_size + 2*padding - filter_size)//stride + 1\n",
        "\n",
        "# Step 1: Simple 1D Conv layer (single channel)\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size, learning_rate=0.01, padding=0, stride=1):\n",
        "        self.filter_size = filter_size\n",
        "        self.lr = learning_rate\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        limit = np.sqrt(6 / filter_size)\n",
        "        self.w = np.random.uniform(-limit, limit, filter_size).astype(np.float64)\n",
        "        self.b = np.float64(0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.astype(np.float64)\n",
        "        self.batch_size = x.shape[0]\n",
        "        if self.padding > 0:\n",
        "            self.x = np.pad(x, ((0,0),(self.padding,self.padding)), 'constant').astype(np.float64)\n",
        "        else:\n",
        "            self.x = x\n",
        "        self.output_size = conv1d_output_size(self.x.shape[1], self.filter_size, padding=0, stride=self.stride)\n",
        "        self.a = np.zeros((self.batch_size, self.output_size), dtype=np.float64)\n",
        "        for n in range(self.batch_size):\n",
        "            for i in range(self.output_size):\n",
        "                start = i*self.stride\n",
        "                end = start+self.filter_size\n",
        "                self.a[n,i] = np.sum(self.x[n,start:end]*self.w) + self.b\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad_output = grad_output.astype(np.float64)\n",
        "        grad_w = np.zeros_like(self.w, dtype=np.float64)\n",
        "        grad_b = grad_output.sum()\n",
        "        grad_x = np.zeros_like(self.x, dtype=np.float64)\n",
        "        for n in range(self.batch_size):\n",
        "            for i in range(self.output_size):\n",
        "                start = i*self.stride\n",
        "                end = start+self.filter_size\n",
        "                grad_w += grad_output[n,i]*self.x[n,start:end]\n",
        "                grad_x[n,start:end] += grad_output[n,i]*self.w\n",
        "        if self.padding>0:\n",
        "            grad_x = grad_x[:,self.padding:-self.padding]\n",
        "        self.w -= self.lr*grad_w\n",
        "        self.b -= self.lr*grad_b\n",
        "        return grad_x\n",
        "\n",
        "# Step 4: Multi-channel 1D Conv layer\n",
        "class Conv1d:\n",
        "    def __init__(self, input_channels, output_channels, filter_size, learning_rate=0.01, padding=0, stride=1):\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.filter_size = filter_size\n",
        "        self.lr = learning_rate\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        limit = np.sqrt(6 / filter_size)\n",
        "        self.w = np.random.uniform(-limit, limit, (output_channels, input_channels, filter_size)).astype(np.float64)\n",
        "        self.b = np.zeros(output_channels, dtype=np.float64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.astype(np.float64)\n",
        "        self.batch_size = x.shape[0]\n",
        "        if self.padding > 0:\n",
        "            self.x = np.pad(x, ((0,0),(0,0),(self.padding,self.padding)), 'constant').astype(np.float64)\n",
        "        else:\n",
        "            self.x = x\n",
        "        self.output_size = conv1d_output_size(self.x.shape[2], self.filter_size, padding=0, stride=self.stride)\n",
        "        self.a = np.zeros((self.batch_size, self.output_channels, self.output_size), dtype=np.float64)\n",
        "        for n in range(self.batch_size):\n",
        "            for o in range(self.output_channels):\n",
        "                for i in range(self.output_size):\n",
        "                    start = i*self.stride\n",
        "                    end = start+self.filter_size\n",
        "                    self.a[n,o,i] = np.sum(self.x[n,:,start:end]*self.w[o,:,:]) + self.b[o]\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad_output = grad_output.astype(np.float64)\n",
        "        grad_w = np.zeros_like(self.w, dtype=np.float64)\n",
        "        grad_b = np.sum(grad_output, axis=(0,2))\n",
        "        grad_x = np.zeros_like(self.x, dtype=np.float64)\n",
        "        for n in range(self.batch_size):\n",
        "            for o in range(self.output_channels):\n",
        "                for i in range(self.output_size):\n",
        "                    start = i*self.stride\n",
        "                    end = start+self.filter_size\n",
        "                    grad_w[o,:,:] += grad_output[n,o,i]*self.x[n,:,start:end]\n",
        "                    grad_x[n,:,start:end] += grad_output[n,o,i]*self.w[o,:,:]\n",
        "        if self.padding>0:\n",
        "            grad_x = grad_x[:,:,self.padding:-self.padding]\n",
        "        self.w -= self.lr*grad_w\n",
        "        self.b -= self.lr*grad_b\n",
        "        return grad_x\n",
        "\n",
        "# Fully connected layer\n",
        "class FullyConnected:\n",
        "    def __init__(self, input_size, output_size, learning_rate=0.01):\n",
        "        limit = np.sqrt(6 / input_size)\n",
        "        self.w = np.random.uniform(-limit, limit, (input_size, output_size)).astype(np.float64)\n",
        "        self.b = np.zeros(output_size, dtype=np.float64)\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x.astype(np.float64)\n",
        "        return self.x @ self.w + self.b\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad_w = self.x.T @ grad_output\n",
        "        grad_b = grad_output.sum(axis=0)\n",
        "        grad_x = grad_output @ self.w.T\n",
        "        self.w -= self.lr * grad_w\n",
        "        self.b -= self.lr * grad_b\n",
        "        return grad_x\n",
        "\n",
        "# Step 3: Small array experiment (forward/backward)\n",
        "x_small = np.array([[1,2,3,4]], dtype=np.float64)\n",
        "w_small = np.array([3,5,7], dtype=np.float64)\n",
        "b_small = np.float64(1.0)\n",
        "delta_a_small = np.array([[10,20]], dtype=np.float64)\n",
        "\n",
        "conv_small = SimpleConv1d(filter_size=3, learning_rate=0.01)\n",
        "conv_small.w = w_small.copy()\n",
        "conv_small.b = b_small\n",
        "out_small = conv_small.forward(x_small)\n",
        "grad_x_small = conv_small.backward(delta_a_small)\n",
        "\n",
        "print(\"Step 3 small array forward:\", out_small)\n",
        "print(\"Step 3 small array backward grad_x:\", grad_x_small)\n",
        "print(\"Step 3 updated weights:\", conv_small.w)\n",
        "print(\"Step 3 updated bias:\", conv_small.b)\n",
        "\n",
        "# Load MNIST (small subset for speed)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train[:1024].reshape(-1,1,28*28).astype(np.float64)/255.0\n",
        "y_train_ohe = to_categorical(y_train[:1024],10).astype(np.float64)\n",
        "x_test = x_test[:256].reshape(-1,1,28*28).astype(np.float64)/255.0\n",
        "y_test_ohe = to_categorical(y_test[:256],10).astype(np.float64)\n",
        "\n",
        "# Initialize multi-channel conv layer for Steps 4+\n",
        "conv = Conv1d(input_channels=1, output_channels=2, filter_size=5, learning_rate=0.0001, padding=2, stride=1)\n",
        "fc = FullyConnected(input_size=2*28*28, output_size=10, learning_rate=0.01)\n",
        "\n",
        "# Step 4/5/6/7/8: MNIST training loop\n",
        "epochs = 1\n",
        "batch_size = 32\n",
        "for e in range(epochs):\n",
        "    for i in range(0,len(x_train),batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train_ohe[i:i+batch_size]\n",
        "        conv_out = conv.forward(x_batch)\n",
        "        conv_out_flat = conv_out.reshape(conv_out.shape[0],-1)\n",
        "        out = fc.forward(conv_out_flat)\n",
        "        loss_grad = (out-y_batch)/batch_size\n",
        "        grad_fc = fc.backward(loss_grad)\n",
        "        grad_conv = grad_fc.reshape(conv_out.shape)\n",
        "        conv.backward(grad_conv)\n",
        "\n",
        "conv_out_test = conv.forward(x_test)\n",
        "conv_out_test_flat = conv_out_test.reshape(conv_out_test.shape[0],-1)\n",
        "out_test = fc.forward(conv_out_test_flat)\n",
        "predictions = np.argmax(out_test,axis=1)\n",
        "accuracy = np.mean(predictions==y_test[:256])\n",
        "print(\"Step 8 Test accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSBhwGfXWeOQ",
        "outputId": "c5e1193e-a3c6-4ea7-b3c2-e9cac9034c42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3 small array forward: [[35. 50.]]\n",
            "Step 3 small array backward grad_x: [[ 30. 110. 170. 140.]]\n",
            "Step 3 updated weights: [2.5 4.2 5.9]\n",
            "Step 3 updated bias: 0.7\n",
            "Step 8 Test accuracy: 0.44140625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZOdMSRZ4We8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}